Homework \#6: Linear Models
================
Pooja Desai (pmd2137)
12/3/2022

## Problem 1

For this problem, we’ll use the 2017 Central Park weather data that
we’ve seen elsewhere. The code chunk below (adapted from the course
website) will download these data.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: ~/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2022-12-03 13:04:35 (8.428)

    ## file min/max dates: 1869-01-01 / 2022-12-31

The boostrap is helpful when you’d like to perform inference for a
parameter / value / summary that doesn’t have an easy-to-write-down
distribution in the usual repeated sampling framework. We’ll focus on a
simple linear regression with tmax as the response and tmin as the
predictor, and are interested in the distribution of two quantities
estimated from these data:

- r̂ 2
- log(β̂ 0∗β̂ 1)

Use 5000 bootstrap samples and, for each bootstrap sample, produce
estimates of these two quantities.

Plot the distribution of your estimates, and describe these in words.

Using the 5000 bootstrap estimates, identify the 2.5% and 97.5%
quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1).

Note: broom::glance() is helpful for extracting r̂ 2 from a fitted
regression, and broom::tidy() (with some additional wrangling) should
help in computing log(β̂ 0∗β̂ 1).

``` r
#Part 1: Plot distribution for R^2 (course provided code)
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

<img src="hw6_pmd2137_files/figure-gfm/weather solution-1.png" width="90%" />

``` r
## Part 2: Plot distribution for log beta (course provided code)
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

<img src="hw6_pmd2137_files/figure-gfm/weather solution-2.png" width="90%" />

## Problem 2: Homidcide Dataset

The Washington Post has gathered data on homicides in 50 large U.S.
cities and made the data available through GitHub. We completed the
following steps to preprocess the data, similar to previous assignments
using this dataset:

First, we created some new variables:

- `city_state` is variable that joins the city and state fields
  (separated by a comma).

- `solved` is a binary variable that denotes whether or not a case was
  solved.

Second, we update the variables to convert `race` and `sex` are factors.
We also convert `age` to a numeric variable. Third, we filter on the
`race` variable to limit the analysis to victims whose race is
identified as Black or White.

Finally, we removed the following `city_state` values because they were
entry errors or did not report victim race: Dallas, TX; Phoenix, AZ;
Kansas City, MO; Tulsa, AL.

``` r
homicides_df <- read.csv("data/homicide-data.csv")  %>%
  janitor::clean_names() %>%
  mutate(city_state = paste(city,state,sep = ", "),
         solved = ifelse(disposition=="Closed by arrest", 1, 0)) %>%
  
  #convert variables to factors and numeric
  mutate(disposition = as.factor(disposition), 
         victim_race = as.factor(victim_race),
         victim_sex = as.factor(victim_sex),
         victim_age = as.numeric(victim_age)) %>%
  
    #filter by victim race
  filter(victim_race %in% c("Black", "White")) %>%

  #remove erroneous city state
  filter(city_state != "Tulsa, AL", 
         city_state != "Dallas, TX", 
         city_state != "Phoenix, AZ", 
         city_state != "Kansas City, MO") -> cleaned_dataset
```

For the city of Baltimore, MD we used the glm function to fit a logistic
regression with case `solved` as the outcome and `victim age`,
`victim_sex` and `victim_race` as predictors.

From we output we obtained estimates, as use them to calculate the
adjusted odds ratio and 95% confidence interval for each of the
predictors. The results are in the table below.

One question of interest was the adjusted odds ratio for solving
homicides comparing *male victims* to *female victims* keeping all other
variables fixed.

Keeping all other varibales constant, the odds of solving cases with
male victims is 0.60. This means male victims have a reduction of 40% in
the odds of their homicide being solved compared to females.

``` r
#construct glm model
homicide_logistic = 
  cleaned_dataset %>%
  glm(solved ~ victim_age + victim_sex + victim_race, data=., family = binomial())

#obtain estimated from model
homicide_logistic %>%
    broom::tidy() %>% 
    
  #calculate odds
    mutate(OR = exp(estimate), #convert to odds
           CI.lower.95 = exp(estimate-(1.96*std.error)), #calculate lower CI @ 95%
           CI.upper.95 = exp(estimate+(1.96*std.error))) %>% #calculate lower CI @ 95%
    select(term, log_OR = estimate, OR, CI.lower.95, CI.upper.95, p.value)
```

    ## # A tibble: 5 × 6
    ##   term                log_OR    OR CI.lower.95 CI.upper.95  p.value
    ##   <chr>                <dbl> <dbl>       <dbl>       <dbl>    <dbl>
    ## 1 (Intercept)        0.358   1.43        1.33        1.54  1.15e-22
    ## 2 victim_age        -0.00216 0.998       0.996       0.999 3.11e- 3
    ## 3 victim_sexMale    -0.506   0.603       0.569       0.639 1.49e-65
    ## 4 victim_sexUnknown -0.0769  0.926       0.498       1.72  8.08e- 1
    ## 5 victim_raceWhite   0.607   1.83        1.73        1.94  1.55e-93

Now run glm for each of the cities in your dataset, and extract the
adjusted odds ratio (and CI) for solving homicides comparing male
victims to female victims. Do this within a “tidy” pipeline, making use
of purrr::map, list columns, and unnest as necessary to create a
dataframe with estimated ORs and CIs for each city.

Create a plot that shows the estimated ORs and CIs for each city.
Organize cities according to estimated OR, and comment on the plot.

## Problem 3:

In this problem, you will analyze data gathered to understand the
effects of several variables on a child’s birthweight. This dataset,
available here, consists of roughly 4000 children and includes the
following variables:

``` r
birthweight <- read.csv("data/birthweight.csv") 
```

        babysex: baby’s sex (male = 1, female = 2)
        bhead: baby’s head circumference at birth (centimeters)
        blength: baby’s length at birth (centimeteres)
        bwt: baby’s birth weight (grams)
        delwt: mother’s weight at delivery (pounds)
        fincome: family monthly income (in hundreds, rounded)
        frace: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown)
        gaweeks: gestational age in weeks
        malform: presence of malformations that could affect weight (0 = absent, 1 = present)
        menarche: mother’s age at menarche (years)
        mheigth: mother’s height (inches)
        momage: mother’s age at delivery (years)
        mrace: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
        parity: number of live births prior to this pregnancy
        pnumlbw: previous number of low birth weight babies
        pnumgsa: number of prior small for gestational age babies
        ppbmi: mother’s pre-pregnancy BMI
        ppwt: mother’s pre-pregnancy weight (pounds)
        smoken: average number of cigarettes smoked per day during pregnancy
        wtgain: mother’s weight gain during pregnancy (pounds)
        Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

Propose a regression model for birthweight. This model may be based on a
hypothesized structure for the factors that underly birthweight, on a
data-driven model-building process, or a combination of the two.
Describe your modeling process and show a plot of model residuals
against fitted values – use add_predictions and add_residuals in making
this plot.

Compare your model to two others:

One using length at birth and gestational age as predictors (main
effects only) One using head circumference, length, sex, and all
interactions (including the three-way interaction) between these Make
this comparison in terms of the cross-validated prediction error; use
crossv_mc and functions in purrr as appropriate.

Note that although we expect your model to be reasonable, model building
itself is not a main idea of the course and we don’t necessarily expect
your model to be “optimal”.
